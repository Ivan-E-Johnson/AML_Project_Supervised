{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:26:12.681025399Z",
     "start_time": "2024-03-13T22:25:51.527260942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.2.0\n",
      "Numpy version: 1.26.3\n",
      "Pytorch version: 2.2.0+cu121\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: c33f1ba588ee00229a309000e888f9817b4f1934\n",
      "MONAI __file__: /home/iejohnson/.venv/AML/lib/python3.10/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.13\n",
      "ITK version: 5.3.0\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: 2.16.2\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.2.0\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning\n",
    "from monai.utils import set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, list_data_collate, decollate_batch, DataLoader\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirst,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstD,\n",
    "    SpatialResampleD,\n",
    "    SpacingD,\n",
    "    ResizeD,\n",
    "    LoadImage,\n",
    "    RandFlipD,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    ToTensor,\n",
    "    RandFlipd, DataStatsD,\n",
    ")\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.networks.nets import UNet\n",
    "from monai.transforms import (\n",
    "    LoadImaged,\n",
    "    ScaleIntensityd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ToTensord,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "print_config()\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "def init_data_lists(base_data_path):\n",
    "    mask_paths = []\n",
    "    image_paths = []\n",
    "    for dir in base_data_path.iterdir():\n",
    "        if dir.is_dir():\n",
    "            image_paths.append(dir / f\"{dir.name}_prostate.nii.gz\")\n",
    "            mask_paths.append(dir / f\"{dir.name}_segmentation.nii.gz\")\n",
    "    return image_paths, mask_paths\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:29:06.901047070Z",
     "start_time": "2024-03-13T22:29:06.814351689Z"
    }
   },
   "id": "d522c5d0fe49c57b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:29:18.078335145Z",
     "start_time": "2024-03-13T22:29:18.001592941Z"
    }
   },
   "id": "e525d999f5d7e289"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "class Net(pytorch_lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._model = UNet(\n",
    "            spatial_dims=3,\n",
    "            in_channels=1,\n",
    "            out_channels=2,\n",
    "            channels=(16, 32, 64, 128, 256),\n",
    "            strides=(2, 2, 2, 2),\n",
    "            num_res_units=2,\n",
    "            norm=Norm.BATCH,\n",
    "        )\n",
    "        self.loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "        self.post_pred = Compose([EnsureType(\"tensor\", device=device), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "        self.post_label = Compose([EnsureType(\"tensor\", device=device), AsDiscrete(to_onehot=2)])\n",
    "        self.dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "        self.best_val_dice = 0\n",
    "        self.best_val_epoch = 0\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._model(x)\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # set up the correct data path\n",
    "\n",
    "        base_data_path = Path(\"/home/iejohnson/programing/Supervised_learning/DATA/SortedProstateData\")\n",
    "        image_paths, mask_paths = init_data_lists(base_data_path)\n",
    "        train_image_paths, test_image_paths, train_mask_paths, test_mask_paths = train_test_split(image_paths, mask_paths, test_size=0.2)\n",
    "        # Prepare data\n",
    "        train_files = [\n",
    "            {\"image\": img_path, \"label\": mask_path}\n",
    "            for img_path, mask_path in zip(train_image_paths, train_mask_paths)\n",
    "        ]\n",
    "        val_files = [\n",
    "            {\"image\": img_path, \"label\": mask_path}\n",
    "            for img_path, mask_path in zip(test_image_paths, test_mask_paths)\n",
    "        ]\n",
    "\n",
    "        RandFlipd_prob = .35\n",
    "        Spacing_dim = (1.5, 1.5, 3.0)\n",
    "        Size_dim = (96,96, 24)\n",
    "        ScaleIntensity_Image = (0, 255)\n",
    "        ScaleIntensity_Mask = (0, 1)\n",
    "        # set deterministic training for reproducibility\n",
    "        set_determinism(seed=0)\n",
    "\n",
    "        # define the data transforms\n",
    "        self.train_transforms = Compose(\n",
    "                [\n",
    "                    LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                    EnsureChannelFirstD(keys=[\"image\", \"label\"]), # Add channel to image and mask so\n",
    "                    SpacingD(keys=[\"image\", \"label\"], pixdim=Spacing_dim, mode=(\"bilinear\", \"nearest\")), # Downsample to 2mm spacing\n",
    "                    ResizeD(keys=[\"image\", \"label\"], spatial_size=Size_dim, mode=(\"bilinear\", \"nearest\")),\n",
    "                    DataStatsD(keys=[\"image\", \"label\"]),\n",
    "                    ScaleIntensityd(keys=[\"image\"], minv=ScaleIntensity_Image[0], maxv=ScaleIntensity_Image[1]),\n",
    "                    ScaleIntensityd(keys=[\"label\"], minv=ScaleIntensity_Mask[0], maxv=ScaleIntensity_Mask[1]), # Coarse Segmentation combine all mask\n",
    "                    RandFlipd(keys=[\"image\", \"label\"], prob=RandFlipd_prob, spatial_axis=0),\n",
    "                    RandFlipd(keys=[\"image\", \"label\"], prob=RandFlipd_prob, spatial_axis=1),\n",
    "                    RandFlipd(keys=[\"image\", \"label\"], prob=RandFlipd_prob, spatial_axis=2),\n",
    "                    DataStatsD(keys=[\"image\", \"label\"]),\n",
    "                    ToTensord(keys=[\"image\", \"label\"]),\n",
    "                ]\n",
    "            )\n",
    "        self.validation_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\", \"label\"]),\n",
    "                EnsureChannelFirstD(keys=[\"image\", \"label\"]), # Add channel to image and mask so \n",
    "                SpacingD(keys=[\"image\", \"label\"], pixdim=Spacing_dim, mode=(\"bilinear\", \"nearest\")), # Downsample to 2mm spacing\n",
    "                ResizeD(keys=[\"image\", \"label\"], spatial_size=Size_dim, mode=(\"bilinear\", \"nearest\")), \n",
    "                DataStatsD(keys=[\"image\", \"label\"]),\n",
    "                ScaleIntensityd(keys=[\"image\"], minv=ScaleIntensity_Image[0], maxv=ScaleIntensity_Image[1]),\n",
    "                ScaleIntensityd(keys=[\"label\"], minv=ScaleIntensity_Mask[0], maxv=ScaleIntensity_Mask[1]), # Coarse Segmentation combine all mask\n",
    "                ToTensord(keys=[\"image\", \"label\"]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # we use cached datasets - these are 10x faster than regular datasets\n",
    "        self.train_ds = CacheDataset(\n",
    "            data=train_files,\n",
    "            transform=self.train_transforms,\n",
    "            cache_rate=1.0,\n",
    "            num_workers=4,\n",
    "        )\n",
    "        self.val_ds = CacheDataset(\n",
    "            data=val_files,\n",
    "            transform=self.validation_transforms,\n",
    "            cache_rate=1.0,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "    #         self.train_ds = monai.data.Dataset(\n",
    "    #             data=train_files, transform=train_transforms)\n",
    "    #         self.val_ds = monai.data.Dataset(\n",
    "    #             data=val_files, transform=val_transforms)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=2,\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            collate_fn=list_data_collate,\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(self.val_ds, batch_size=1, num_workers=4)\n",
    "        return val_loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self._model.parameters(), 1e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        output = self.forward(images)\n",
    "        loss = self.loss_function(output, labels)\n",
    "        tensorboard_logs = {\"train_loss\": loss.item()}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch[\"image\"], batch[\"label\"]\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        outputs = sliding_window_inference(images, roi_size, sw_batch_size, self.forward)\n",
    "        loss = self.loss_function(outputs, labels)\n",
    "        outputs = [self.post_pred(i) for i in decollate_batch(outputs)]\n",
    "        labels = [self.post_label(i) for i in decollate_batch(labels)]\n",
    "        self.dice_metric(y_pred=outputs, y=labels)\n",
    "        d = {\"val_loss\": loss, \"val_number\": len(outputs)}\n",
    "        self.validation_step_outputs.append(d)\n",
    "        return d\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_loss, num_items = 0, 0\n",
    "        for output in self.validation_step_outputs:\n",
    "            val_loss += output[\"val_loss\"].sum().item()\n",
    "            num_items += output[\"val_number\"]\n",
    "        mean_val_dice = self.dice_metric.aggregate().item()\n",
    "        self.dice_metric.reset()\n",
    "        mean_val_loss = torch.tensor(val_loss / num_items)\n",
    "        tensorboard_logs = {\n",
    "            \"val_dice\": mean_val_dice,\n",
    "            \"val_loss\": mean_val_loss,\n",
    "        }\n",
    "        if mean_val_dice > self.best_val_dice:\n",
    "            self.best_val_dice = mean_val_dice\n",
    "            self.best_val_epoch = self.current_epoch\n",
    "        print(\n",
    "            f\"current epoch: {self.current_epoch} \"\n",
    "            f\"current mean dice: {mean_val_dice:.4f}\"\n",
    "            f\"\\nbest mean dice: {self.best_val_dice:.4f} \"\n",
    "            f\"at epoch: {self.best_val_epoch}\"\n",
    "        )\n",
    "        self.validation_step_outputs.clear()  # free memory\n",
    "        return {\"log\": tensorboard_logs}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:35:14.329692296Z",
     "start_time": "2024-03-13T22:35:14.043945020Z"
    }
   },
   "id": "8f0cb007c5332242"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:35:14.858181306Z",
     "start_time": "2024-03-13T22:35:14.633183711Z"
    }
   },
   "id": "9ef25bb056117a6c"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Loading dataset:   0%|          | 0/78 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.1920299082994461, 989.436767578125)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (1.130395531654358, 1185.0257568359375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 677.26171875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 874.3577270507812)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   5%|▌         | 4/78 [00:01<00:22,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.1450338065624237, 1095.5965576171875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 888.2916870117188)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 821.314697265625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 907.0242309570312)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:   9%|▉         | 7/78 [00:02<00:26,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 789.9951171875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 706.7233276367188)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 905.443359375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1095.882568359375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  13%|█▎        | 10/78 [00:03<00:23,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 783.4566650390625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  17%|█▋        | 13/78 [00:04<00:12,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 969.4183959960938)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 876.296630859375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  19%|█▉        | 15/78 [00:04<00:13,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 676.6674194335938)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 918.4242553710938)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1086.8961181640625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1021.9364013671875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  23%|██▎       | 18/78 [00:05<00:16,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 829.40576171875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 919.7138061523438)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 880.5087890625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  28%|██▊       | 22/78 [00:06<00:11,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 889.5608520507812)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  29%|██▉       | 23/78 [00:06<00:11,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1066.206787109375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  31%|███       | 24/78 [00:06<00:11,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.185671865940094, 1040.18701171875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1025.23046875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  33%|███▎      | 26/78 [00:07<00:12,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 967.4465942382812)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  35%|███▍      | 27/78 [00:07<00:12,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 943.2785034179688)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 939.1167602539062)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 891.756103515625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  36%|███▌      | 28/78 [00:08<00:25,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 895.7363891601562)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 914.0029296875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.10361310839653015, 943.8056640625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  42%|████▏     | 33/78 [00:09<00:11,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 850.4325561523438)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1193.11279296875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  45%|████▍     | 35/78 [00:09<00:10,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 815.16943359375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 907.5302124023438)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  47%|████▋     | 37/78 [00:10<00:10,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 971.752685546875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  49%|████▊     | 38/78 [00:10<00:09,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 874.5751953125)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  50%|█████     | 39/78 [00:10<00:08,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 936.4508056640625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 911.751953125)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  53%|█████▎    | 41/78 [00:11<00:08,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 898.286865234375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  54%|█████▍    | 42/78 [00:11<00:09,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 826.128662109375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 938.965087890625)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  55%|█████▌    | 43/78 [00:11<00:08,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 787.9010620117188)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  58%|█████▊    | 45/78 [00:12<00:09,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 700.8966674804688)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  59%|█████▉    | 46/78 [00:12<00:08,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 815.9989013671875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 836.2699584960938)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1095.494140625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  63%|██████▎   | 49/78 [00:13<00:07,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.07079944014549255, 1165.9625244140625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  64%|██████▍   | 50/78 [00:13<00:07,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 782.2423095703125)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 892.2327270507812)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  67%|██████▋   | 52/78 [00:14<00:05,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 988.5175170898438)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  68%|██████▊   | 53/78 [00:14<00:05,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 994.996337890625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 724.2698974609375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  71%|███████   | 55/78 [00:15<00:05,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 883.551025390625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  72%|███████▏  | 56/78 [00:15<00:05,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 789.71484375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1043.87255859375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  74%|███████▍  | 58/78 [00:15<00:04,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 852.314453125)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  76%|███████▌  | 59/78 [00:15<00:04,  4.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 869.2816162109375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 887.3565673828125)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 742.701904296875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  77%|███████▋  | 60/78 [00:16<00:06,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1000.29296875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1051.557373046875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 877.0448608398438)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  83%|████████▎ | 65/78 [00:17<00:03,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 949.9344482421875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  85%|████████▍ | 66/78 [00:17<00:02,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 827.357421875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  86%|████████▌ | 67/78 [00:18<00:02,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 996.9198608398438)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1047.098876953125)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  87%|████████▋ | 68/78 [00:18<00:03,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1184.5706787109375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 882.4727172851562)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  91%|█████████ | 71/78 [00:19<00:01,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 969.4267578125)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 973.5504150390625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  94%|█████████▎| 73/78 [00:19<00:00,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 725.018310546875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.36504411697387695, 1115.179443359375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  95%|█████████▍| 74/78 [00:19<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 895.280517578125)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  97%|█████████▋| 76/78 [00:19<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (2.2198309898376465, 1152.1531982421875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 810.642822265625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 78/78 [00:19<00:00,  3.93it/s]\n",
      "Loading dataset:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (2.038743257522583, 1163.148681640625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 753.48291015625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 784.2161865234375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1022.5721435546875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  10%|█         | 2/20 [00:00<00:07,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.05474795773625374, 1051.8348388671875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.28657299280166626, 926.1520385742188)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 999.72802734375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  35%|███▌      | 7/20 [00:01<00:02,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 951.837646484375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  40%|████      | 8/20 [00:01<00:02,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 875.88427734375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 755.0615844726562)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 923.203125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  50%|█████     | 10/20 [00:02<00:02,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.19226540625095367, 1435.017333984375)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  60%|██████    | 12/20 [00:02<00:01,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 647.9819946289062)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 946.1903076171875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  70%|███████   | 14/20 [00:03<00:01,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 905.1012573242188)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 626.65087890625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  75%|███████▌  | 15/20 [00:03<00:01,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.05971883609890938, 886.9005126953125)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 996.2890625)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset:  85%|████████▌ | 17/20 [00:04<00:00,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 955.1619873046875)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 804.7142944335938)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 20/20 [00:04<00:00,  4.89it/s]\n",
      "\n",
      "  | Name          | Type     | Params\n",
      "-------------------------------------------\n",
      "0 | _model        | UNet     | 4.8 M \n",
      "1 | loss_function | DiceLoss | 0     \n",
      "-------------------------------------------\n",
      "4.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.8 M     Total params\n",
      "19.236    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]current epoch: 0 current mean dice: 0.0010\n",
      "best mean dice: 0.0010 at epoch: 0\n",
      "Epoch 0:   0%|          | 0/39 [00:00<?, ?it/s]                            Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 255.0)\n",
      "Data statistics:\n",
      "Type: <class 'monai.data.meta_tensor.MetaTensor'> torch.float32\n",
      "Shape: torch.Size([1, 96, 96, 24])\n",
      "Value range: (0.0, 1.0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 3 but got size 4 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 19\u001B[0m\n\u001B[1;32m     10\u001B[0m trainer \u001B[38;5;241m=\u001B[39m pytorch_lightning\u001B[38;5;241m.\u001B[39mTrainer(\n\u001B[1;32m     11\u001B[0m     max_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m600\u001B[39m,\n\u001B[1;32m     12\u001B[0m     logger\u001B[38;5;241m=\u001B[39mtb_logger,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     15\u001B[0m     log_every_n_steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[1;32m     16\u001B[0m )\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# train\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:544\u001B[0m, in \u001B[0;36mTrainer.fit\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m TrainerStatus\u001B[38;5;241m.\u001B[39mRUNNING\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 544\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    545\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[1;32m    546\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001B[0m, in \u001B[0;36m_call_and_handle_interrupt\u001B[0;34m(trainer, trainer_fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mlauncher\u001B[38;5;241m.\u001B[39mlaunch(trainer_fn, \u001B[38;5;241m*\u001B[39margs, trainer\u001B[38;5;241m=\u001B[39mtrainer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n\u001B[1;32m     47\u001B[0m     _call_teardown_hook(trainer)\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:580\u001B[0m, in \u001B[0;36mTrainer._fit_impl\u001B[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[0m\n\u001B[1;32m    573\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    574\u001B[0m ckpt_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_checkpoint_connector\u001B[38;5;241m.\u001B[39m_select_ckpt_path(\n\u001B[1;32m    575\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfn,\n\u001B[1;32m    576\u001B[0m     ckpt_path,\n\u001B[1;32m    577\u001B[0m     model_provided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    578\u001B[0m     model_connected\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    579\u001B[0m )\n\u001B[0;32m--> 580\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstopped\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:987\u001B[0m, in \u001B[0;36mTrainer._run\u001B[0;34m(self, model, ckpt_path)\u001B[0m\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_signal_connector\u001B[38;5;241m.\u001B[39mregister_signal_handlers()\n\u001B[1;32m    984\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    985\u001B[0m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[1;32m    986\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[0;32m--> 987\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    989\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    990\u001B[0m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[1;32m    991\u001B[0m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[1;32m    992\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: trainer tearing down\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1033\u001B[0m, in \u001B[0;36mTrainer._run_stage\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1031\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_sanity_check()\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mset_detect_anomaly(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_detect_anomaly):\n\u001B[0;32m-> 1033\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1034\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected state \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:205\u001B[0m, in \u001B[0;36m_FitLoop.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_start()\n\u001B[0;32m--> 205\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end()\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:363\u001B[0m, in \u001B[0;36m_FitLoop.advance\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_fetcher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 363\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch_loop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_fetcher\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:140\u001B[0m, in \u001B[0;36m_TrainingEpochLoop.run\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdone:\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 140\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_advance_end(data_fetcher)\n\u001B[1;32m    142\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_restarting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py:250\u001B[0m, in \u001B[0;36m_TrainingEpochLoop.advance\u001B[0;34m(self, data_fetcher)\u001B[0m\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_training_batch\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    248\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mlightning_module\u001B[38;5;241m.\u001B[39mautomatic_optimization:\n\u001B[1;32m    249\u001B[0m         \u001B[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001B[39;00m\n\u001B[0;32m--> 250\u001B[0m         batch_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautomatic_optimization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    252\u001B[0m         batch_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmanual_optimization\u001B[38;5;241m.\u001B[39mrun(kwargs)\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:190\u001B[0m, in \u001B[0;36m_AutomaticOptimization.run\u001B[0;34m(self, optimizer, batch_idx, kwargs)\u001B[0m\n\u001B[1;32m    183\u001B[0m         closure()\n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;66;03m# BACKWARD PASS\u001B[39;00m\n\u001B[1;32m    187\u001B[0m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[1;32m    188\u001B[0m \u001B[38;5;66;03m# gradient update with accumulated gradients\u001B[39;00m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 190\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    192\u001B[0m result \u001B[38;5;241m=\u001B[39m closure\u001B[38;5;241m.\u001B[39mconsume_result()\n\u001B[1;32m    193\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:268\u001B[0m, in \u001B[0;36m_AutomaticOptimization._optimizer_step\u001B[0;34m(self, batch_idx, train_step_and_backward_closure)\u001B[0m\n\u001B[1;32m    265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_progress\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep\u001B[38;5;241m.\u001B[39mincrement_ready()\n\u001B[1;32m    267\u001B[0m \u001B[38;5;66;03m# model hook\u001B[39;00m\n\u001B[0;32m--> 268\u001B[0m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_lightning_module_hook\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moptimizer_step\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_step_and_backward_closure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m should_accumulate:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptim_progress\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep\u001B[38;5;241m.\u001B[39mincrement_completed()\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:157\u001B[0m, in \u001B[0;36m_call_lightning_module_hook\u001B[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m hook_name\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[LightningModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpl_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 157\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m    160\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1303\u001B[0m, in \u001B[0;36mLightningModule.optimizer_step\u001B[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001B[0m\n\u001B[1;32m   1264\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimizer_step\u001B[39m(\n\u001B[1;32m   1265\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1266\u001B[0m     epoch: \u001B[38;5;28mint\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1269\u001B[0m     optimizer_closure: Optional[Callable[[], Any]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1270\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1271\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001B[39;00m\n\u001B[1;32m   1272\u001B[0m \u001B[38;5;124;03m    the optimizer.\u001B[39;00m\n\u001B[1;32m   1273\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1301\u001B[0m \n\u001B[1;32m   1302\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1303\u001B[0m     \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer_closure\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py:152\u001B[0m, in \u001B[0;36mLightningOptimizer.step\u001B[0;34m(self, closure, **kwargs)\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_strategy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 152\u001B[0m step_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_strategy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_on_after_step()\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m step_output\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:239\u001B[0m, in \u001B[0;36mStrategy.optimizer_step\u001B[0;34m(self, optimizer, closure, model, **kwargs)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001B[39;00m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, pl\u001B[38;5;241m.\u001B[39mLightningModule)\n\u001B[0;32m--> 239\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecision_plugin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:122\u001B[0m, in \u001B[0;36mPrecision.optimizer_step\u001B[0;34m(self, optimizer, model, closure, **kwargs)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001B[39;00m\n\u001B[1;32m    121\u001B[0m closure \u001B[38;5;241m=\u001B[39m partial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_closure, model, optimizer, closure)\n\u001B[0;32m--> 122\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/optim/optimizer.py:385\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    380\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    381\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    382\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    383\u001B[0m             )\n\u001B[0;32m--> 385\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    388\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/optim/adam.py:146\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m closure \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39menable_grad():\n\u001B[0;32m--> 146\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups:\n\u001B[1;32m    149\u001B[0m     params_with_grad \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision.py:108\u001B[0m, in \u001B[0;36mPrecision._wrap_closure\u001B[0;34m(self, model, optimizer, closure)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_wrap_closure\u001B[39m(\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     97\u001B[0m     model: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpl.LightningModule\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     98\u001B[0m     optimizer: Optimizer,\n\u001B[1;32m     99\u001B[0m     closure: Callable[[], Any],\n\u001B[1;32m    100\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    101\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001B[39;00m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;124;03m    hook is called.\u001B[39;00m\n\u001B[1;32m    103\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    106\u001B[0m \n\u001B[1;32m    107\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 108\u001B[0m     closure_result \u001B[38;5;241m=\u001B[39m \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_after_closure(model, optimizer)\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m closure_result\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:144\u001B[0m, in \u001B[0;36mClosure.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[Tensor]:\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\u001B[38;5;241m.\u001B[39mloss\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:129\u001B[0m, in \u001B[0;36mClosure.closure\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39menable_grad()\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclosure\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ClosureResult:\n\u001B[0;32m--> 129\u001B[0m     step_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_step_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m step_output\u001B[38;5;241m.\u001B[39mclosure_loss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    132\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwarning_cache\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`training_step` returned `None`. If this was on purpose, ignore this warning...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/automatic.py:318\u001B[0m, in \u001B[0;36m_AutomaticOptimization._training_step\u001B[0;34m(self, kwargs)\u001B[0m\n\u001B[1;32m    315\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\n\u001B[1;32m    317\u001B[0m \u001B[38;5;66;03m# manually capture logged metrics\u001B[39;00m\n\u001B[0;32m--> 318\u001B[0m training_step_output \u001B[38;5;241m=\u001B[39m \u001B[43mcall\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtraining_step\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mpost_training_step()  \u001B[38;5;66;03m# unused hook - call anyway for backward compatibility\u001B[39;00m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_result_cls\u001B[38;5;241m.\u001B[39mfrom_training_step_output(training_step_output, trainer\u001B[38;5;241m.\u001B[39maccumulate_grad_batches)\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:309\u001B[0m, in \u001B[0;36m_call_strategy_hook\u001B[0;34m(trainer, hook_name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mprofile(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 309\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n\u001B[1;32m    312\u001B[0m pl_module\u001B[38;5;241m.\u001B[39m_current_fx_name \u001B[38;5;241m=\u001B[39m prev_fx_name\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:391\u001B[0m, in \u001B[0;36mStrategy.training_step\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module:\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_redirection(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlightning_module, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining_step\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 391\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlightning_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[29], line 117\u001B[0m, in \u001B[0;36mNet.training_step\u001B[0;34m(self, batch, batch_idx)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtraining_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch, batch_idx):\n\u001B[1;32m    116\u001B[0m     images, labels \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m\"\u001B[39m], batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 117\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_function(output, labels)\n\u001B[1;32m    119\u001B[0m     tensorboard_logs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m: loss\u001B[38;5;241m.\u001B[39mitem()}\n",
      "Cell \u001B[0;32mIn[29], line 22\u001B[0m, in \u001B[0;36mNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 22\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/monai/networks/nets/unet.py:303\u001B[0m, in \u001B[0;36mUNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 303\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/monai/networks/layers/simplelayers.py:129\u001B[0m, in \u001B[0;36mSkipConnection.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 129\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcat\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat([x, y], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdim)\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/monai/networks/layers/simplelayers.py:129\u001B[0m, in \u001B[0;36mSkipConnection.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 129\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcat\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat([x, y], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdim)\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/monai/networks/layers/simplelayers.py:132\u001B[0m, in \u001B[0;36mSkipConnection.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    129\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubmodule(x)\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcat\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 132\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124madd\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39madd(x, y)\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/monai/data/meta_tensor.py:276\u001B[0m, in \u001B[0;36mMetaTensor.__torch_function__\u001B[0;34m(cls, func, types, args, kwargs)\u001B[0m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    275\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 276\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__torch_function__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;66;03m# if \"out\" in kwargs:\u001B[39;00m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;66;03m#     return ret\u001B[39;00m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _not_requiring_metadata(ret):\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/_tensor.py:1418\u001B[0m, in \u001B[0;36mTensor.__torch_function__\u001B[0;34m(cls, func, types, args, kwargs)\u001B[0m\n\u001B[1;32m   1415\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[1;32m   1417\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _C\u001B[38;5;241m.\u001B[39mDisableTorchFunctionSubclass():\n\u001B[0;32m-> 1418\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1419\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func \u001B[38;5;129;01min\u001B[39;00m get_default_nowrap_functions():\n\u001B[1;32m   1420\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Expected size 3 but got size 4 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# initialise the LightningModule\n",
    "net = Net()\n",
    "\n",
    "\n",
    "# set up loggers and checkpoints\n",
    "log_dir = os.path.join(\"/home/iejohnson/PycharmProjects/AML/AML_Project_Supervised\", \"logs\")\n",
    "tb_logger = pytorch_lightning.loggers.TensorBoardLogger(save_dir=log_dir)\n",
    "\n",
    "# initialise Lightning's trainer.\n",
    "trainer = pytorch_lightning.Trainer(\n",
    "    max_epochs=600,\n",
    "    logger=tb_logger,\n",
    "    enable_checkpointing=True,\n",
    "    num_sanity_val_steps=1,\n",
    "    log_every_n_steps=16,\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.fit(net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:35:43.726768712Z",
     "start_time": "2024-03-13T22:35:15.011020143Z"
    }
   },
   "id": "1bb2cdd310a03660"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Net' object has no attribute 'train_ds'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# walk through transformed data\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m----> 3\u001B[0m     img, mask \u001B[38;5;241m=\u001B[39m \u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_ds\u001B[49m[i]\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(img\u001B[38;5;241m.\u001B[39mshape, mask\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      5\u001B[0m     plt\u001B[38;5;241m.\u001B[39mfigure(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheck\u001B[39m\u001B[38;5;124m\"\u001B[39m, (\u001B[38;5;241m12\u001B[39m, \u001B[38;5;241m6\u001B[39m))\n",
      "File \u001B[0;32m~/.venv/AML/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1686\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1687\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1688\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Net' object has no attribute 'train_ds'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:34:36.862713601Z",
     "start_time": "2024-03-13T22:34:36.536891313Z"
    }
   },
   "id": "63d813312f1259da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a15cd59577d5769"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
